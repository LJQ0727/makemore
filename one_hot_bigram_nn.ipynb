{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<S>', 'hi', ',', 'how', 'are', 'you', 'doing', '?', 'i', \"'m\", 'fine', '.', 'how', 'about', 'yourself', '?', '<E>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2512"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bigram_nn\n",
    "\n",
    "import torch\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "with open('chatbot.txt') as f:\n",
    "    sents = f.readlines()\n",
    "    sent_words = [word_tokenize(words) for words in sents]\n",
    "    for i, words in enumerate(sent_words):\n",
    "        # words = [word for word in words if word.isalpha()]\n",
    "        words = [word.lower() for word in words]\n",
    "        words.insert(0, '<S>')\n",
    "        words.append('<E>')\n",
    "        sent_words[i] = words\n",
    "\n",
    "\n",
    "print(sent_words[0])\n",
    "\n",
    "\n",
    "word_set = set()\n",
    "for sent in sent_words:\n",
    "    for word in sent:\n",
    "        word_set.add(word)\n",
    "\n",
    "word_cnt = len(word_set)\n",
    "\n",
    "word_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "# tensorize\n",
    "\n",
    "word_to_idx = {word:i for i,word in enumerate(word_set)}\n",
    "idx_to_word = {i:word for i,word in enumerate(word_set)}\n",
    "\n",
    "# building bigram\n",
    "bigram = torch.zeros((word_cnt, word_cnt), dtype=torch.float64)\n",
    "\n",
    "for sent in sent_words:\n",
    "    for i in range(len(sent)-1):\n",
    "        first_idx = word_to_idx[sent[i]]\n",
    "        second_idx = word_to_idx[sent[i+1]]\n",
    "        # bigram[first_idx, second_idx] += 1\n",
    "\n",
    "        # append to the input of nn\n",
    "        xs.append(first_idx)\n",
    "        ys.append(second_idx)\n",
    "\n",
    "# torch.sum(bigram, dim=1)\n",
    "# smoothing\n",
    "# bigram += 1\n",
    "# bigram = bigram / torch.sum(bigram, dim=1)\n",
    "\n",
    "# APPLY SOFTMAX\n",
    "# bigram = torch.softmax(bigram, dim=1)\n",
    "\n",
    "# bigram[422]\n",
    "\n",
    "# bigram[422] /= torch.sum(bigram[422])\n",
    "# torch.sum(bigram[422])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64466, 2512])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "xenc = F.one_hot(xs, num_classes=word_cnt).float().to(device)\n",
    "yenc = F.one_hot(ys, num_classes=word_cnt).float().to(device)\n",
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normal distribution\n",
    "# # initialize weight of first layer\n",
    "\n",
    "n_neuron = 27\n",
    "\n",
    "# W = torch.randn((word_cnt, n_neuron))\n",
    "# (xenc @ W).shape\n",
    "# # the firing rate of each of the neurons to each of the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weight of output layer\n",
    "W_2 = torch.randn((n_neuron, word_cnt))\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(word_cnt, n_neuron)\n",
    "        self.out_layer = nn.Linear(n_neuron, word_cnt)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        return F.softmax(self.out_layer(x), dim=1)\n",
    "\n",
    "\n",
    "model = Model().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.8288, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.8246, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.7365, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6774, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6762, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6762, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6762, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6760, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6756, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6752, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6750, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6732, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6539, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6535, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6533, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6532, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6531, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6530, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6527, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6490, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6438, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6327, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6315, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6295, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6292, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6241, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6200, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6197, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6194, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6193, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6192, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6190, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6186, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6117, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.6059, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5925, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5893, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5892, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5890, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5888, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5887, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5887, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5881, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5875, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5865, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5864, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5864, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5863, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5862, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5861, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5852, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5852, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5849, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5846, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5844, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5844, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5844, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5843, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5843, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5839, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5837, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5834, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5833, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5830, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5829, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5828, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5828, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5828, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5828, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5828, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5828, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5826, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5826, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5820, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5769, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5716, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5711, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5708, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5708, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5705, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5702, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5702, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5701, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5699, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5699, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5697, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5695, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5692, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5690, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5690, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5689, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5689, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5689, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5688, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5686, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5685, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5685, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5685, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5685, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(7.5685, device='cuda:0', grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(xenc)\n",
    "    loss = F.cross_entropy(out, yenc)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 10 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample and generate sent\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(curr_word):\n",
    "    while True:\n",
    "        curr_idx = word_to_idx[curr_word]\n",
    "        vec = torch.zeros((1, word_cnt), dtype=torch.float).to(device)\n",
    "        vec[0,curr_idx] = 1\n",
    "        prediction = idx_to_word[torch.argmax(model(vec)).item()]\n",
    "        if prediction == '<E>':\n",
    "            return\n",
    "        else:\n",
    "            print(prediction)\n",
    "            curr_word = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "weather\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "generate_sentence('pushed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1253ed567b0ae1ea4d701ec237c6bbcbcaa1d71f1734265b697d2876df359bdf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
